{"posts":[{"title":"CSUR22 - Anomaly Detection and Failure Root Cause Analysis in (Micro)Service-based Cloud Applications A Survey","text":"总结 故障检测和根因定位的综述 当前的异常检测技术，都需要一个baseline去构建预知识。当线上执行差距过大（并发压力、环境、基础测试集构建错误等），会造成检测不准确 根因定位技术：各有千秋。基于拓扑的、概率/格兰杰假设的貌似会找出更多相关或者更接近根本的问题，相比基于trace比较的 摘要 检测故障和识别可能的根本原因，对于迅速恢复和修复应用程序至关重要 对现代多业务应用中当前可用的异常检测和根本原因分析技术进行结构化概述和定性分析 本论文结构为 异常检测技术 基于log的异常检测 基于分布式trace的异常检测 基于监控数据的异常检测 根因分析技术 基于log的 基于trace的 基于监控数据的 Intro 向微服务松耦合变化 但是难以区分单独故障还是级联故障(多个服务jiaohu)，难以检测和理解故障 目前异常检测(发现)和根因定位互相剥离，观察是否有相辅相成的工具【但目前我看到的大多异常检测和根因定位一起做】 术语 异常：服务响应时间变慢、吞吐降低or记录错误事件 根因分析与调试技术的区别：根本原因分析技术只是分析应用程序运行时收集的信息(例如，日志或监控数据)，而不是在不同的条件下重新运行它【无关紧要的区别】 监控内容：KPIs(关键性能指标), log, trace 异常检测 基于log的异常检测 无监督学习baseline，在线分析log是否与baseline是否相同 OASIS [58]: 先运行一个无错误的应用，提取log，挖掘一个控制流图，对正常条件下的基线应用行为进行建模。内含：应该由哪个服务记录哪些事件，记录的顺序是什么 然后，通过将新生成的日志映射到相应的模板，并检查到达的日志模板是否符合控制流图，实现在线异常检测。如果在相应的时间延迟中没有记录应该遵循模板的模板，或者遵循给定模板的模板的实际速率明显偏离预期的分支概率，那么OASIS认为应用程序受到了功能异常的影响。 LogSed [34]: 时间加权流程图 总结： 共同假设：类似的事件会有类似的log。 但实际上服务是动态的，可能导致检测假阳性/假阴性 基于分布式追踪数据的异常检测 trace获取 + （无监督/监督机器学习 | trace比较技术） 常见的假设是，应用程序在训练运行中产生的轨迹与运行时产生的轨迹是一致的，因此提供了一个基线，用来比较新产生的轨迹。 无监督机器学习 在生产前训练无监督网络，侦测生产过程中的问题 TraceAnomaly [45]: 如果有新数据，则检查白名单，再给出阈值表示是否异常 Nedelkoski [61]: LSTM 监督学习 标记+训练+判断 MEPFL: 复旦WisdomCode团队工作 ((20220330164333-6snty44 ‘WisdomCode-MEPFL-基于日志学习的错误预测与故障定位’)) trace对比技术 trace相似度比较。收集多服务应用程序中可能出现的轨迹，然后检查新收集的轨迹是否与已收集的轨迹相似。 缺点：应用程序继续与以前的运行保持一致的情况下再次进行的，以前收集的跟踪提供了一个基线，用于比较新收集的跟踪。因此，当应用程序的运行时条件与收集基线轨迹时不同时，制定的异常检测的准确性可能会降低。 Meng et al. [54] and Wang et al. [88]：预生成trace调用树 -&gt; 新trace计算编辑距离，如歌超过阈值，则异常; 预生成响应时间矩阵 -&gt; 主成分分析。 缺点：计算复杂度 Chen et al. [17]: 使用fast matrix sketching algorithm做异常检测，优点：快 基于监控信息的异常检测 需要在无错误模式训练，然后在生产环境中定位问题。当应用程序运行时条件有所不同,检测的准确性可能减少,例如:由于高负荷由最终用户请求的山峰,或者由于新服务部署到取代过时的 监控数据 SLI，全名Service Level Indicator，是服务等级指标的简称，它是衡定系统稳定性的指标。一个常见的SLI是请求得到正常响应的百分比。 SLO，全名Sevice Level Objective，是服务等级目标的简称，也是稳定性目标,是围绕SLI构建的目标, 比如，月度、季度、年度等。 无监督学习 学习他们行为的基线模型。然后使用基线模型在线检测服务上新监控的kpi是否偏离基线模型 MicroRCA[92]:并不算无监督，相当于图建模 ((20220510163942-ddm9aru ‘NOMS20-MicroRCA-Root Cause Localization of Performance Issues in…’)) CloudRanger[87]: 应用程序的前端服务上实施持续学习，以根据监控的响应时间、负载和吞吐量，了解当前条件下的预期响应时间。 基于历史初始模型的脱机训练 当应用程序运行时，CloudRanger对监控的kpi应用多项式回归来更新基线模型，以反映应用程序在动态变化的运行时条件下的行为。 然后，根据给定的容错阈值，通过检查应用程序前端的响应时间是否明显偏离预期时间来实施在线异常检测。 监督学习 正常运行、注入特定的故障，生成训练集 SLO检测 ϵ-diagnosis [76]: 注重尾延迟 Heartbeating 根因定位 基于log的根因定位 建模，then确认异常 Aggarwal et al. [1]: 因果关系图的顶点对应用程序服务进行建模，而因果关系图的有向弧则对源服务中的异常可能导致目标服务中的异常进行建模; 时间序列建模，计算格兰杰因果关系，确定错误记录之间的因果性 随机游走确定根因 基于trace的根因定位 方法：①可视化 ②统计分析 ③拓扑分析 可视化 Zhou et al. [98]: ((20211126002021-vogdt0p ‘ITSE21-Fault Analysis and Debugging of Microservice Systems: Ind…’)) 统计分析 CloudDiag [56]: 变异系数, 阈值判断。基于主成分分析处理 TraceAnomaly [45]: 神经网络，根据执行时间，把trace分为正常异常。每个响应时间与平均响应时间有显著偏差的服务交互都被认为是异常的 基于图 MonitorRank [38]: 基于图的随机游走 MicroHECL [44]： BFS, 找到异常, 用某种方法遍历所有节点，看节点传播能否到达异常 基于监控数据的根因定位 大多数基于监视的根本原因分析技术都依赖相关性作为驱动因素，以识别所观察到的异常的可能根本原因。其思想是，在异常服务上监控的kpi与在其他服务上并行监控的kpi之间的相关性越高，后者导致在前者上观察到的异常的可能性就越大 然而，考虑到相关性并不能确保因果关系，服务中观察到的异常的实际根本原因可能不在其监控kpi与异常服务高度相关的服务中，而在其他服务中。因此，伪相关性会影响利用KPI相关性进行统计分析或驱动拓扑/因果关系图中查找根本原因的技术。这增加了假阴性的风险，通常通过返回多个可能值来解决次问题 统计分析 Wang et al. [86]: 通过识别其监控kpi与检测到的异常同时异常的应用程序服务，可以确定服务上检测到的异常的根本原因 PAL [63]: CUSUM(累积和)图度量监视的KPI值的变化幅度，包括监视值的原始序列和自举序列，而自举序列是对所监视的KPI值进行随机排序的排列。如果原始序列的变化幅度高于大多数bootstrap，则认为原始序列是异常的，并根据其CUSUM图确定异常开始的时间。减少误报：为了减少误报，PAL和FChain检查异常是否影响了所有应用程序服务，在这种情况下，异常被归类为外部原因(如工作负载峰值)。相反，如果只有应用程序服务的子集异常，则认为它们是前端异常的可能根源，并按照异常开始时间的顺序返回它们。错误定位：最早的异常确实被认为是最有可能的根本原因，因为它们可能已经从相应的服务传播到其他服务，直到导致观测到的前端异常。 基于图的分析 randomwalk：MicroRCA 其他方法，格兰杰因果测试等 因果关系图分析 PC-algorithm BFS Random Walk 原理总结 因果图中的顶点要么为应用程序[18,19,24,42,43,48,50,87]建模，要么为这些服务上监视的KPI[51, 55, 68]建模，而每个弧线表示目标服务/KPI的性能取决于源服务/KPI的性能。 因果关系图总是通过对日志事件/监控kpi的时间序列应用pc -算法[82]来获得(但对于LOUD[51])，因为已知该算法允许确定时间序列中的因果关系，即:通过确定一个时间序列中的值是否可以用来预测另一个时间序列的值 搜索方法：从异常节点(服务/kpi)出发，BFS或者Random Walk randomwalk: 访问具有随机步长服务的概率与该服务的性能与观察到异常的服务之间的相关性成正比 讨论 成本 精度 假阳性解决方法 基线模型：不断训练新的模型 trace解决方法：将新观察到的信息和之前的所有信息进行比较 可解释性和对策","link":"/2023/01/09/CSUR22%20-%20Anomaly%20Detection%20and%20Failure%20Root%20Cause%20Analysis%20in%20(Micro)Service-based%20Cloud%20Applications%20A%20Survey/"},{"title":"NSDI19 - Zeno - Zeno Diagnosing Performance Problems with Temporal Provenance","text":"总结 提出了时序建模分析，精准刻画请求延时来源 提出了一个工具，给定trace中的两个事件，能刻画事件之间调用链以及为什么第二个事件慢 并不是用来分析系统性能问题，更多的是一种查询显示工具 背景 诊断问题时，定位瓶颈只是第一步。例如定位到网络延时、服务器负载。但正在的问题可能在于通过瓶颈链路发送流量的其他服务，或者通过请求使服务过载的机器。 Intro 现有工具无法解决的问题：假设一台配置错误的机器向存储后端发送大量rpc，该后端过载并延迟了来自其他客户机的请求。 M过多的请求阻塞了真正需要服务的机器C的请求 注意拿咖啡的例子 现有的方法在这种情况下不能满足的原因是它们只关注函数因果关系，它们解释了为什么给定的计算会有某些特定的结果。这种解释只关注计算的直接输入:例如，如果我们想解释一杯咖啡的存在，我们可以关注咖啡豆的来源、杯子的来源和咖啡师的行为。相比之下，时间因果关系也可能涉及其他看似不相关的计算:例如，买咖啡花了太长时间的原因可能是在我们前面等候的顾客太多，而这反过来可能是其他地方的交通堵塞导致大量顾客路过当地商店的结果。同时，在解释延迟时，一些功能依赖性可能被证明是不相关的:例如，即使咖啡豆是制作咖啡所需要的，它们也可能不是造成延迟的原因，因为它们已经在商店中可以买到。 本文更注重于时序因果(temporal causality)，而dapper更注重于功能因果（functional causality) 本文提出一种时序因果的概念和方法，以及如何将其与现有的诊断技术相结合 Overview M对B的请求被称为off-path cause 在google cloud platform中，发现2014年1月至2016年5月，我们选择了所有95个事件报告，既描述了症状，也描述了原因。我们发现超过三分之一(34.7%)的事故是时间错误 传统的trace树 无法确定什么是瓶颈根因 Provenance Provenance：表示一种方法。当操作员要求对某个感兴趣的事件(例如，包的到达)进行解释时，系统可以生成一个递归解释，将事件与一组原因(如包的原始传输和相关路由状态)联系起来。 Approach ① 捕获并简历系统处理请求的顺序 - 定性分析 ② 时间推理和调度理论中的关键路径分析之间的联系 - 时间贡献度计算 - 定量分析 ③ 可视化 Temporal provenance 序列边 dapper的调用关系为因果边，系统调用的顺序为序列边 序列边表示一台机器上事件的处理先后顺序 INS表示事件触发，DRV表示事件处理。黑色线表示因果：A会触发B、C。绿色虚线表示先后，A事件，接着B被处理，接着C被处理。（注意这种表示方法和dapper不一样） 查询 目的：探究请求和响应之间延时的原因 形式：T-Query(e1, e2)，要求e1,e2需要有因果关系 算法 查询经典来源 P:=Query(e2)，则e1一定会包含在p中 识别p中所有 有因果边连接但没有顺序边连接的点(v1,v2)，则v2因为一些原因被延迟(例如上图的C和B，没有因果边，C可能被某些事件延迟) 不断增加路径和事件，最终得到延迟原因 延迟注释：贡献度计算 目的：判断每个子树对整体延时的贡献度 规则：(作者提出三条规则，总结为两条人话) 规则一：整体延时由后向前，递归得分配耗时 A在5s结束，发现B结束用了4s，C结束用了2s，时间递归分配 规则二：无法分配的延时，按照潜在的speed-up分配 难点：A在6s开始，是因为B很慢导致，还是E很慢导致。(X,Y为两台机器) 可以发现，如果B提前，则A不可能提前，因为被E阻塞，要等E返回。但E提前，A会被提前。所以给DRV(B)分配了4s，剩下的B到A的时间，以及E自己的时间，被分给了E请求接收、处理、发送 可视化 为什么可视化：①e1,e2之间事件包含的过多 ②有很多类似的事件可能导致延时。这些会导致整个图看起来很乱 可视化方法 子图分割：递归得，分为若干个事件 分为绿和红，红也要同级事件分割 子图聚合：两个顶点，如果类似则合并 提高可视化 Zeno 作者对RapidNet进行监控分析 作者使用Google dapper 监控一个应用，并通过dapper获取了时序关系和因果关系，在必要的锁争用的地方使用dtrace捕获关系[Q] 作者监控交换机来完成另一个场景的分析 诊断场景 错误的维护任务导致排队 API延迟变高 额外的负载（向每个实例发布更新） 锁争用 作业队列增长 网络拥塞 [Q] 如果dapper的话，事件之间不应该有空格(尤其是作者已经特别标注了网络事件的请求和接收)","link":"/2023/01/11/NSDI19-Zeno-Zeno-Diagnosing-Performance-Problems-with-Temporal-Provenance/"}],"tags":[{"name":"微服务","slug":"微服务","link":"/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"性能分析","slug":"性能分析","link":"/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"}],"categories":[{"name":"论文笔记","slug":"论文笔记","link":"/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"微服务性能分析","slug":"论文笔记/微服务性能分析","link":"/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"}],"pages":[{"title":"about","text":"","link":"/about/index.html"}]}